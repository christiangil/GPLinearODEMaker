var documenterSearchIndex = {"docs":
[{"location":"glo/#GPLinearODE-(GLO)-struct","page":"GPLinearODE struct","title":"GPLinearODE (GLO) struct","text":"","category":"section"},{"location":"glo/","page":"GPLinearODE struct","title":"GPLinearODE struct","text":"The GPLinearODEMaker.GLO object is used to ensure that all of the necessary pieces exist to specify the GLOM model.","category":"page"},{"location":"glo/","page":"GPLinearODE struct","title":"GPLinearODE struct","text":"GPLinearODEMaker.GLO","category":"page"},{"location":"glo/#GPLinearODEMaker.GLO","page":"GPLinearODE struct","title":"GPLinearODEMaker.GLO","text":"GLO{T1<:Real, T2<:Integer} a.k.a. GPLinearODE\n\nA structure that holds all of the relevant information for constructing the GLOM model\n\nArguments\n\nkernel::Function: kernel function for the latent Gaussian process (GP)\nn_kern_hyper::T2: amount of hyperparameters for the kernel function\nn_dif::T2: amount of times you are differenting the base kernel\nn_out::T2: amount of outputs you are jointly modelling\nx_obs::Vector{T1}: the observation times/phases\ny_obs::Vector{T1}: the flattened, observed data\nnoise::Vector{T1}: the measurement noise at all observations (σ, not σ^2)\nnormals::Vector{T1}: the normalization of each section of y_obs\na::Matrix{T1}: the meta kernel coefficients\nnon_zero_hyper_inds::Vector{T2}: the indices of the non-zero hyperparameters\ncoeff_orders::AbstractArray{T2,6}: The powers that each a coefficient is taken to for each part of the covariance matrix construction. Used for constructing differentiated versions of the kernel\ncoeff_coeffs::AbstractArray{T2,4}: The coefficients that each a coefficient is multiplied by for each part of the covariance matrix construction. Used for constructing differentiated versions of the kernel\ncovariance::Array{T1, 3}: the measurement covariance at all observations\nhas_covariance::Bool: Whether or not there are measurement covariances (as opposed to just having measurement noises)\nkernel_changes_with_output::Bool: A flag for if the kernel is not the same for each output (e.g. there is a time delay kernel hyperparameter that changes)\n\n\n\n\n\n","category":"type"},{"location":"glo/","page":"GPLinearODE struct","title":"GPLinearODE struct","text":"It is often normalized before any optimizations to make the process more amenable to numerical methods","category":"page"},{"location":"glo/","page":"GPLinearODE struct","title":"GPLinearODE struct","text":"GPLinearODEMaker.normalize_GLO!","category":"page"},{"location":"glo/#GPLinearODEMaker.normalize_GLO!","page":"GPLinearODE struct","title":"GPLinearODEMaker.normalize_GLO!","text":"normalize_GLO!(glo)\n\nStandardize the outputs in glo.y_obs (and glo.noise) to have 0-mean and unit variance and store the normalization in glo.normals\n\n\n\n\n\nnormalize_GLO!(glo, renorms)\n\nDivide the outputs in glo.y_obs and glo.noise and multiply glo.normals by renorms\n\n\n\n\n\n","category":"function"},{"location":"nlogl/#GLOM-Functionality","page":"GLOM Functionality","title":"GLOM Functionality","text":"","category":"section"},{"location":"nlogl/","page":"GLOM Functionality","title":"GLOM Functionality","text":"Modules = [GPLinearODEMaker]\nPages   = [\"src/gp_functions.jl\"]","category":"page"},{"location":"nlogl/#GPLinearODEMaker.nlogL_matrix_workspace","page":"GLOM Functionality","title":"GPLinearODEMaker.nlogL_matrix_workspace","text":"nlogL_matrix_workspace{T<:Real}\n\nA structure that holds all of the relevant information for calculating nlogL() derivatives. Used to prevent recalculations during optimization.\n\nArguments\n\nnlogL_hyperparameters::Vector: The current hyperparameters\nΣ_obs::Cholesky: The covariance matrix based on nlogL_hyperparameters\n∇nlogL_hyperparameters::Vector: The nlogl gradient at nlogL_hyperparameters\nβs::Vector{Matrix}: List of inv(Σ) * dΣ_dθ where dΣ_dθ is the partial derivative of Σ w.r.t. each nlogL_hyperparameters\n\n\n\n\n\n","category":"type"},{"location":"nlogl/#GPLinearODEMaker.GP_posteriors-Union{Tuple{T}, Tuple{Function,Array{T,1},Array{T,1},Array{T,1},Array{T,1},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.GP_posteriors","text":"GP_posteriors(kernel_func, x_obs, y_obs, x_samp, measurement_noise, kernel_hyperparameters; return_mean_obs=false, kwargs...)\n\nCalculate the posterior mean and std at x_samp, (optionally) posterior mean at x_obs and (optionally) the posterior covariance matrix for the GP described by kernel_func and kernel_hyperparameters\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.GP_posteriors-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.GP_posteriors","text":"GP_posteriors(glo, x_samp, total_hyperparameters; return_mean_obs=false, y_obs=glo.y_obs, kwargs...)\n\nCalculate the posterior mean and std at x_samp, (optionally) posterior mean at glo.x_obs and (optionally) the posterior covariance matrix for the GP described by glo and total_hyperparameters\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.GP_posteriors-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.GP_posteriors","text":"GP_posteriors(glo, total_hyperparameters; y_obs=glo.y_obs, kwargs...)\n\nCalculate the posterior mean at glo.x_obs for the GP described by glo and total_hyperparameters\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.GP_posteriors_from_covariances-Union{Tuple{T}, Tuple{Array{T,1},LinearAlgebra.Cholesky,LinearAlgebra.Symmetric}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.GP_posteriors_from_covariances","text":"GP_posteriors_from_covariances(y_obs, Σ_obs, Σ_obs_raw)\n\nCalculate the observed posterior mean for the GP used to calculate Σ_obs and Σ_obs_raw\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.GP_posteriors_from_covariances-Union{Tuple{T}, Tuple{Array{T,1},Union{Array{T,2}, LinearAlgebra.Cholesky, LinearAlgebra.Symmetric},LinearAlgebra.Cholesky,Union{Array{T,2}, LinearAlgebra.Symmetric},Union{Array{T,2}, LinearAlgebra.Transpose{T,Array{T,2}}, LinearAlgebra.Symmetric},LinearAlgebra.Symmetric}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.GP_posteriors_from_covariances","text":"GP_posteriors_from_covariances(y_obs, Σ_samp, Σ_obs, Σ_samp_obs, Σ_obs_samp, Σ_obs_raw; return_Σ=true, kwargs...)\n\nCalculate the sampled posterior mean and std, observed posterior mean, and (optionally) the posterior covariance matrix for the GP used to calculate Σ_samp, Σ_obs, Σ_samp_obs, Σ_obs_samp, and Σ_obs_raw\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.GP_posteriors_from_covariances-Union{Tuple{T}, Tuple{Array{T,1},Union{Array{T,2}, LinearAlgebra.Cholesky, LinearAlgebra.Symmetric},LinearAlgebra.Cholesky,Union{Array{T,2}, LinearAlgebra.Symmetric},Union{Array{T,2}, LinearAlgebra.Transpose{T,Array{T,2}}, LinearAlgebra.Symmetric}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.GP_posteriors_from_covariances","text":"GP_posteriors_from_covariances(y_obs, Σ_samp, Σ_obs, Σ_samp_obs, Σ_obs_samp; return_Σ=true, kwargs...)\n\nCalculate the sampled posterior mean and std and (optionally) the posterior covariance matrix for the GP used to calculate Σ_samp, Σ_obs, Σ_samp_obs, and Σ_obs_samp\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker._covariance!-Union{Tuple{T2}, Tuple{T1}, Tuple{Array{T1,2},Function,Array{T1,1},Array{T1,1},Array{T1,1},Array{T2,1},Bool,Bool,Bool}} where T2<:Integer where T1<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker._covariance!","text":"covariance!(Σ::Matrix, kernelfunc, x1list, x2list, kernelhyperparameters, dorder, symmetric, samex, equal_spacing)\n\nFills Σ serially with a covariance matrix by evaluating kernel_func with kernel_hyperparametersfor each pair of x1list and x2list entries. Be careful using a function that starts with a _.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker._covariance!-Union{Tuple{T2}, Tuple{T1}, Tuple{SharedArrays.SharedArray{T1,2},Function,Array{T1,1},Array{T1,1},Array{T1,1},Array{T2,1},Bool,Bool,Bool}} where T2<:Integer where T1<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker._covariance!","text":"_covariance!(Σ::SharedArray, kernel_func, x1list, x2list, kernel_hyperparameters, dorder, symmetric, same_x, equal_spacing)\n\nFills Σ in parallel with a covariance matrix by evaluating kernel_func with kernel_hyperparametersfor each pair of x1list and x2list entries. Be careful using a function that starts with a _.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.calculate_shared_nlogL_matrices!-Tuple{GPLinearODEMaker.nlogL_matrix_workspace,GPLinearODEMaker.GLO,Array{var\"#s93\",1} where var\"#s93\"<:Real}","page":"GLOM Functionality","title":"GPLinearODEMaker.calculate_shared_nlogL_matrices!","text":"calculate_shared_nlogL_matrices!(workspace, glo, non_zero_hyperparameters)\n\nCalculates the quantities shared by the nlogL and ∇nlogL calculations and stores them in the existing workspace\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.calculate_shared_nlogL_matrices-Tuple{GPLinearODEMaker.GLO,Array{var\"#s90\",1} where var\"#s90\"<:Real}","page":"GLOM Functionality","title":"GPLinearODEMaker.calculate_shared_nlogL_matrices","text":"calculate_shared_nlogL_matrices(glo, non_zero_hyperparameters; Σ_obs=Σ_observations(glo, reconstruct_total_hyperparameters(glo, non_zero_hyperparameters); ignore_asymmetry=true))\n\nCalculates the quantities shared by the nlogL and ∇nlogL calculations\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.calculate_shared_∇nlogL_matrices!-Tuple{GPLinearODEMaker.nlogL_matrix_workspace,GPLinearODEMaker.GLO,Array{var\"#s90\",1} where var\"#s90\"<:Real}","page":"GLOM Functionality","title":"GPLinearODEMaker.calculate_shared_∇nlogL_matrices!","text":"calculate_shared_∇nlogL_matrices!(workspace, glo, non_zero_hyperparameters)\n\nCalculates the quantities shared by the ∇nlogL and ∇∇nlogL calculations and stores them in the existing workspace\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.calculate_shared_∇nlogL_matrices-Tuple{GPLinearODEMaker.GLO,Array{var\"#s89\",1} where var\"#s89\"<:Real}","page":"GLOM Functionality","title":"GPLinearODEMaker.calculate_shared_∇nlogL_matrices","text":"calculate_shared_∇nlogL_matrices(glo, non_zero_hyperparameters; kwargs...)\n\nCalculates the quantities shared by the ∇nlogL and ∇∇nlogL calculations\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.coefficient_orders-Union{Tuple{T}, Tuple{Integer,Integer}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.coefficient_orders","text":"coefficient_orders(n_out, n_dif; a=ones(n_out, n_dif))\n\nFind the powers that each GLOM coefficient is taken to for each part of the matrix construction before differentiating by any hyperparameters.\n\nOutputs\n\ncoeff_orders::Array{Int, 6}: filled with integers for what power each coefficient is taken to in the construction of a given block of the total covariance matrix. For example, coeff_orders[1,1,2,3,:,:] would tell you the powers of each coefficient (:,:) that are multiplied by the covariance matrix constructed by evaluating the partial derivative of the kernel (once by t1 and twice by t2) at every pair of time points (2,3) in the construction of the first block of the total covariance matrix (1,1)\ncoeff_coeffs::Array{Int, 4}: Filled with ones anywhere that coeff_orders indicates that coefficients exists to multiply a given covariance matrix for a given block\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.covariance!-Union{Tuple{T2}, Tuple{T1}, Tuple{DenseArray{T1,2},Function,Array{T1,1},Array{T1,1},Array{T1,1}}} where T2<:Integer where T1<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.covariance!","text":"covariance!(Σ, kernel_func, x1list, x2list, kernel_hyperparameters; dorder=zeros(Int64, 2 + length(kernel_hyperparameters)), symmetric=false)\n\nFills Σ with a covariance matrix by evaluating kernel_func with kernel_hyperparametersfor each pair of x1list and x2list entries.\n\nKeyword Arguments\n\ndorder::Vector{T2}=zeros(Int64, 2 + length(kernel_hyperparameters)): How often to differentiate the covariance function w.r.t each kernel_hyperparameter. (i.e. dorder=[1, 0, 1] would correspond to differenting once w.r.t. the first and third kernel_hyperparameter)\nsymmetric::Bool=false: If you know that the resulting covariance matrix should be symmetric, setting this to true can reduce redundant calculations\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.covariance-Tuple{GPLinearODEMaker.GLO,Array{var\"#s90\",1} where var\"#s90\"<:Real}","page":"GLOM Functionality","title":"GPLinearODEMaker.covariance","text":"covariance(glo, total_hyperparameters; kwargs...)\n\nCalculates the total GLOM covariance matrix by combining the latent covariance matrices implied by glo at each glo.x_obs\n\nSee also: covariance\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.covariance-Tuple{GPLinearODEMaker.GLO,Array{var\"#s91\",1} where var\"#s91\"<:Real,Array{var\"#s92\",1} where var\"#s92\"<:Real,Array{var\"#s93\",1} where var\"#s93\"<:Real}","page":"GLOM Functionality","title":"GPLinearODEMaker.covariance","text":"covariance(glo, x1list, x2list, total_hyperparameters; dΣdθs_total=Int64[], kwargs...)\n\nCalculates the total GLOM covariance matrix by combining the latent covariance matrices implied by glo for each pair of x1list and x2list entries.\n\nNotable Arguments\n\ntotal_hyperparameters::Vector: The current a values (GLOM coeffients that describe how to combine the differentiated versions of the latent GP) followed by the kernel_hyperparameters (i.e. lengthscales and periods)\ndΣdθs_total=Int64[]: Which of the total_hyperparameters to differentiate the covariance function w.r.t. (i.e. for a glo with 6 a values and 2 kernel hyperparameters, dΣdθs_total=[4, 8] would correspond to differenting once w.r.t. the fourth a value and second kernel hyperparameter)\n\nSee also: covariance!\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.covariance-Union{Tuple{T1}, Tuple{Function,Array{T1,1},Array{T1,1},Array{T1,1}}} where T1<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.covariance","text":"covariance(kernel_func, x1list, x2list, kernel_hyperparameters; kwargs...)\n\nCalculates a covariance matrix by evaluating kernel_func with kernel_hyperparametersfor each pair of x1list and x2list entries.\n\nSee also: covariance!\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.covariance_permutations-Union{Tuple{T}, Tuple{Function,Array{T,1},Array{T,1},Array{T,1},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.covariance_permutations","text":"covariance_permutations(kernel_func, x_obs, x_samp, measurement_noise, kernel_hyperparameters; return_both=false)\n\nCalculate all of the different versions of the covariance matrices using kernel_func with kernel_hyperparameters between each of the pairs of x_obs and x_samp and themselves.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.covariance_permutations-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.covariance_permutations","text":"covariance_permutations(glo, x_samp, total_hyperparameters; return_both=false)\n\nCalculate all of the different versions of the covariance matrices using the glo GP with total_hyperparameters between each of the pairs of glo.x_obs and x_samp and themselves.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.d2nlogLdθ-Union{Tuple{T}, NTuple{4,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.d2nlogLdθ","text":"d2nlogLdθ(y2, y12, α, α1)\n\nSecond partial derivative of nlogL(Σ, y) w.r.t. two parameters that affect y\n\nArguments\n\ny2::Vector: The derivative of observations w.r.t the second parameter at each time point\ny12::Vector: The derivative of observations w.r.t the both parameters at each time point\nα::Vector: inv(Σ) * y\nα1::Vector: inv(Σ) * y1 where y1 is the derivative of observations w.r.t the first parameter at each time point\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.d2nlogLdθ-Union{Tuple{T}, Tuple{Array{T,1},Array{T,1},Array{T,1},Array{T,1},Array{T,2}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.d2nlogLdθ","text":"d2nlogLdθ(y, y1, α, α1, β2)\n\nSecond partial derivative of nlogL(Σ, y) w.r.t. a parameter that affects y and a hyperparameter that affects Σ\n\nArguments\n\ny::Vector: The observations at each time point\ny1::Vector: The derivative of observations w.r.t the y-affecting parameter at each time point\nα::Vector: inv(Σ) * y\nα1::Vector: inv(Σ) * y1 where y1 is the derivative of observations w.r.t the first parameter at each time point\nβ2::Matrix: inv(Σ) * dΣ_dθ where dΣ_dθ is the partial derivative of the Σ w.r.t. the Σ-affecting hyperparameter\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.d2nlogLdθ-Union{Tuple{T}, Tuple{Array{T,1},Array{T,1},Array{T,2},Array{T,2},Array{T,2}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.d2nlogLdθ","text":"d2nlogLdθ(y, α, β1, β2, β12)\n\nSecond partial derivative of nlogL(Σ, y) w.r.t. two hyperparameters that affect Σ\n\nArguments\n\ny::Vector: The observations at each time point\nα::Vector: inv(Σ) * y\nβ1::Matrix: inv(Σ) * dΣ_dθ where dΣ_dθ is the partial derivative of the Σ w.r.t. the first hyperparameter\nβ2::Matrix: Same as β1 but for the second hyperparameter\nβ12::Matrix: inv(Σ_obs) * d2Σ_dθ1dθ2 where d2Σ_dθ1dθ2 is the partial derivative of the covariance matrix Σ_obs w.r.t. both of the hyperparameters being considered\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.dif_coefficients!-Union{Tuple{T}, Tuple{Integer,Integer,Array{T,1},AbstractArray{T,6},AbstractArray{T,4}}} where T<:Integer","page":"GLOM Functionality","title":"GPLinearODEMaker.dif_coefficients!","text":"dif_coefficients!(n_out, n_dif, dΣdθs_total::Vector, coeff_orders, coeff_coeffs)\n\nModify coeff_orders and coeff_coeffs with the coefficients for constructing differentiated version of the kernel (for the differentiations implied by dΣdθ_totals) using the powers that each coefficient is taken to for each part of the matrix construction\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.dif_coefficients!-Union{Tuple{T}, Tuple{Integer,Integer,Integer,AbstractArray{T,6},AbstractArray{T,4}}} where T<:Integer","page":"GLOM Functionality","title":"GPLinearODEMaker.dif_coefficients!","text":"dif_coefficients!(n_out, n_dif, dΣdθ_total::Int, coeff_orders, coeff_coeffs)\n\nModify coeff_orders and coeff_coeffs with the coefficients for constructing differentiated version of the kernel (for the differentiation implied by dΣdθ_total) using the powers that each coefficient is taken to for each part of the matrix construction\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.dnlogLdθ-Union{Tuple{T}, Tuple{Array{T,1},Array{T,1},Array{T,2}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.dnlogLdθ","text":"dnlogLdθ(y, α, β)\n\nFirst partial derivative of nlogL(Σ, y) w.r.t. hyperparameters that affect Σ\n\nArguments\n\ny::Vector: The observations at each time point\nα::Vector: inv(Σ) * y\nβ::Matrix: inv(Σ) * dΣ_dθ where dΣ_dθ is the partial derivative of the Σ w.r.t. a hyperparameter\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.dnlogLdθ-Union{Tuple{T}, Tuple{Array{T,1},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.dnlogLdθ","text":"dnlogLdθ(y1, α)\n\nFirst partial derivative of nlogL(Σ, y) w.r.t. hyperparameters that affect y\n\nArguments\n\ny1::Vector: The derivative of observations at each time point\nα::Vector: inv(Σ) * y\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.get_σ-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.get_σ","text":"get_σ(glo, x_samp, total_hyperparameters)\n\nCalculate the glo GP (using total_hyperparameters) posterior standard deviation at each x_samp point.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.get_σ-Union{Tuple{T}, Tuple{LinearAlgebra.LowerTriangular{T,Array{T,2}},Union{Array{T,2}, LinearAlgebra.Transpose{T,Array{T,2}}, LinearAlgebra.Symmetric},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.get_σ","text":"get_σ(L_obs, Σ_obs_samp, diag_Σ_samp)\n\nCalculate the GP posterior standard deviation at each sampled point. Algorithm 2.1 from Rasmussen and Williams\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.include_kernel-Tuple{AbstractString}","page":"GLOM Functionality","title":"GPLinearODEMaker.include_kernel","text":"include_kernel(kernel_name)\n\nTries to include the specified kernel, assuming it was included with GLOM. Returns the kernel function and number of hyperparameters it uses\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.nlogL-Union{Tuple{T}, Tuple{Union{LinearAlgebra.Cholesky, LinearAlgebra.Diagonal},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.nlogL","text":"nlogL(Σ, y; α= Σ \\ y, nlogL_normalization=logdet(Σ)+length(y)*log(2*π))\n\nNegative log likelihood for data y assuming it was drawn from a multivariate normal distribution with 0 mean and covariance Σ (usually Σ + noise)\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.nlogL_GLOM!-Union{Tuple{T}, Tuple{GPLinearODEMaker.nlogL_matrix_workspace,GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.nlogL_GLOM!","text":"nlogL_GLOM!(workspace, glo, total_hyperparameters; y_obs=copy(glo.y_obs))\n\nNegative log likelihood for glo using total_hyperparameters to construct the covariance matrix and storing the intermediate results in workspace.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.nlogL_GLOM","text":"nlogL_GLOM(glo, total_hyperparameters; y_obs=copy(glo.y_obs), kwargs...)\n\nNegative log likelihood for glo using the non-zero total_hyperparameters to construct the covariance matrix.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.prep_parallel_covariance-Tuple{AbstractString,AbstractString}","page":"GLOM Functionality","title":"GPLinearODEMaker.prep_parallel_covariance","text":"prep_parallel_covariance(kernel_name, kernel_path; kwargs...)\n\nMake it easy to run the covariance calculations on many processors. Makes sure every worker has access to kernel function, importing it from the kernel_path.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.prep_parallel_covariance-Tuple{AbstractString}","page":"GLOM Functionality","title":"GPLinearODEMaker.prep_parallel_covariance","text":"prep_parallel_covariance(kernel_name; kwargs...)\n\nMake it easy to run the covariance calculations on many processors. Makes sure every worker has access to kernel function.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.reconstruct_total_hyperparameters-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.reconstruct_total_hyperparameters","text":"reconstruct_total_hyperparameters(glo, hyperparameters)\n\nReinsert the zero coefficients into the non-zero hyperparameter list if needed\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.Σ_observations-Union{Tuple{T}, Tuple{Function,Array{T,1},Array{T,1},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.Σ_observations","text":"Σ_observations(kernel_func, x_obs, measurement_noise, kernel_hyperparameters; ignore_asymmetry=false, return_both)\n\nCalculates the covariance matrix of kernel_func at x_obs and adds measurement_noise^2 to the diagonal and performs a Cholesky factorization. Optionally returns the Σ back as well.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.Σ_observations-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.Σ_observations","text":"Σ_observations(glo, total_hyperparameters; ignore_asymmetry=false, return_both=false)\n\nCalculates a Cholesky decomposition of the GLOM covariance matrix implied by glo and total_hyperparameters including glo.noise or glo.covariance on the (block) diagonal\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.Σ_observations-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T,Array{T,2}},Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.Σ_observations","text":"Σ_observations(Σ, measurement_noise::Vector; return_both=false, kwargs...)\n\nAdd measurement_noise^2 to the diagonal of Σ and performs a Cholesky factorization. Optionally returns the Σ back as well.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.Σ_observations-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T,Array{T,2}},Array{T,3}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.Σ_observations","text":"Σ_observations(Σ, measurement_covariance::Array{T, 3}; return_both=false, kwargs...)\n\nAdd measurement_covariance to the block diagonal of Σ and performs a Cholesky factorization. Optionally returns the Σ back as well.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.∇nlogL-Union{Tuple{T}, Tuple{Array{T,1},Array{T,1},Array{Array{T,2},1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.∇nlogL","text":"∇nlogL(y, α, βs)\n\nGradient of nlogL(Σ, y) w.r.t. hyperparameters that affect Σ\n\nArguments\n\ny::Vector: The observations at each time point\nα::Vector: inv(Σ) * y\nβs::Vector{Matrix}: List of inv(Σ) * dΣ_dθ where dΣ_dθ is the partial derivative of Σ w.r.t. each hyperparameter\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.∇nlogL_GLOM!-Union{Tuple{T}, Tuple{GPLinearODEMaker.nlogL_matrix_workspace,GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.∇nlogL_GLOM!","text":"∇nlogL_GLOM!(workspace, glo, total_hyperparameters; y_obs=copy(glo.y_obs))\n\nnlogL gradient for glo using the non-zero total_hyperparameters to construct the covariance matrices and storing the intermediate results in workspace.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.∇nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.∇nlogL_GLOM","text":"∇nlogL_GLOM(glo, total_hyperparameters; y_obs=copy(glo.y_obs), kwargs...)\n\nnlogL gradient for glo using the non-zero total_hyperparameters to construct the covariance matrices.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.∇∇nlogL_GLOM!-Union{Tuple{T}, Tuple{GPLinearODEMaker.nlogL_matrix_workspace,GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.∇∇nlogL_GLOM!","text":"∇∇nlogL_GLOM!(workspace, glo, total_hyperparameters; y_obs=copy(glo.y_obs))\n\nnlogL Hessian for glo using the non-zero total_hyperparameters to construct the covariance matrices and storing the intermediate results in workspace.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.∇∇nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1},LinearAlgebra.Cholesky,Array{T,1},Array{T,1},Array{Array{T,2},1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.∇∇nlogL_GLOM","text":"∇∇nlogL_GLOM(glo, total_hyperparameters, Σ_obs, y_obs, α, βs)\n\nnlogL Hessian for glo using the non-zero total_hyperparameters to construct the covariance matrices.\n\n\n\n\n\n","category":"method"},{"location":"nlogl/#GPLinearODEMaker.∇∇nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"GLOM Functionality","title":"GPLinearODEMaker.∇∇nlogL_GLOM","text":"∇∇nlogL_GLOM(glo, total_hyperparameters; y_obs=copy(glo.y_obs))\n\nnlogL Hessian for glo using the non-zero total_hyperparameters to construct the covariance matrices.\n\n\n\n\n\n","category":"method"},{"location":"indices/#Functions","page":"Indices","title":"Functions","text":"","category":"section"},{"location":"indices/","page":"Indices","title":"Indices","text":"Order   = [:function]","category":"page"},{"location":"indices/#Types","page":"Indices","title":"Types","text":"","category":"section"},{"location":"indices/","page":"Indices","title":"Indices","text":"Order   = [:type]","category":"page"},{"location":"kernel_creation/#GLOM-Kernel-Creation","page":"Adding new kernels","title":"GLOM Kernel Creation","text":"","category":"section"},{"location":"kernel_creation/","page":"Adding new kernels","title":"Adding new kernels","text":"GLOM requires latent GP kernels that are at least twice mean-square differentiable in order to ensure that second order derivatives exist for non-trivial model construction. All of the derived versions of the kernels that are necessary can be created using the following function.","category":"page"},{"location":"kernel_creation/","page":"Adding new kernels","title":"Adding new kernels","text":"Modules = [GPLinearODEMaker]\nPages   = [\"src/kernel_creation_functions.jl\"]","category":"page"},{"location":"kernel_creation/#GPLinearODEMaker.include_lag_kernel-Tuple{String}","page":"Adding new kernels","title":"GPLinearODEMaker.include_lag_kernel","text":"include_lag_kernel(kernel_name)\n\nProvides a kernel for modelling two variables with the same shared latent GP,     but with a lag term between them using one of GLOM's base kernels. The     returned kernel function should be called with the lag hyperparameter     appended to the end of the hyperparameters for the base kernel.\n\nArguments\n\nkernel_name::String: The base kernel function to use. Passed to includekernel(kernelname)\n\n\n\n\n\n","category":"method"},{"location":"kernel_creation/#GPLinearODEMaker.kernel_coder-Tuple{SymEngine.Basic,String}","page":"Adding new kernels","title":"GPLinearODEMaker.kernel_coder","text":"kernel_coder(symbolic_kernel_original, kernel_name; periodic_var=\"\", cutoff_var=\"\", loc=\"src/kernels/\")\n\nCreates the necessary differentiated versions of base kernels required by GLOM and saves the script containing them to loc\n\nArguments\n\nsymbolic_kernel_original::Basic: Kernel function created using variables declared with SymEngine's @vars macro\nkernel_name::String: The name the kernel function will be saved with\nperiodic_var::String=\"\": If changed, tries to convert the named variable (currently only one) into a periodic variable by replacing it with 2*sin(π*δ/periodic_var)\ncutoff_var::String=\"\": If changed, makes the kernel return 0 for abs(δ) > cutoff_var\nloc::String=\"src/kernels/\": The location where the script will be saved\n\nExtra Info\n\nThe created function will look like this\n\n$kernel_name(hyperparameters::Vector{<:Real}, δ::Real; dorder::Vector{<:Integer}=zeros(Int64, length(hyperparameters) + 2))\n\nFor example, you could define a kernel like so:\n\n\"Radial basis function GP kernel (aka squared exonential, ~gaussian)\"\nfunction se_kernel_base(λ::Number, δ::Number)\n    return exp(-δ ^ 2 / (2 * λ ^ 2))\nend\n\nAnd then calculate the necessary derivative versions like so:\n\n@vars δ λ\nkernel_coder(se_kernel_base(λ, δ), \"se\")\n\nThe function is saved in loc * kernel_name * \"_kernel.jl\", so you can use it with a command akin to this:\n\ninclude(loc * kernel_name * \"_kernel.jl\")\n\nSee also: include_kernel\n\n\n\n\n\n","category":"method"},{"location":"kernel_creation/","page":"Adding new kernels","title":"Adding new kernels","text":"All of the premade kernels that are included with GLOM (in src/kernels) were created with this example script","category":"page"},{"location":"diagnostic/#Diagnostic-functions","page":"Diagnostic functions","title":"Diagnostic functions","text":"","category":"section"},{"location":"diagnostic/","page":"Diagnostic functions","title":"Diagnostic functions","text":"Modules = [GPLinearODEMaker]\nPages   = [\"src/diagnostic_functions.jl\"]","category":"page"},{"location":"diagnostic/#GPLinearODEMaker.est_dΣdθ-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"Diagnostic functions","title":"GPLinearODEMaker.est_dΣdθ","text":"est_dΣdθ(glo, kernel_hyperparameters; return_est=true, return_anal=false, return_dif=false, return_bool=false, dif=1e-6, print_stuff=true)\n\nEstimate the covariance derivatives of glo (a GLOM model) at kernel_hyperparameterswith forward differences\n\nKeyword Arguments\n\nreturn_est::Bool=true: Add the numerically estimated dΣdθs to the output\nreturn_anal::Bool=false: Add the analytical dΣdθs to the output\nreturn_dif::Bool=false: Add the difference between the dΣdθs to the output\nreturn_bool::Bool=false: Return just a similarity Boolean\ndif::Real=1e-6: The step size used in the forward difference method\nprint_stuff::Bool=true: Whether to print things\n\nOutput\n\nIf return_bool==true, returns a Boolean for whether the analytical and\n\nnumerical estimates for the dΣdθs are approximately the same.\n\nElse returns a vector with some combination of the numerically estimated\n\ndΣdθs, analytical dΣdθs, and differences between them\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.est_∇-Tuple{Function,Array{var\"#s89\",1} where var\"#s89\"<:Real}","page":"Diagnostic functions","title":"GPLinearODEMaker.est_∇","text":"est_∇(f::Function, inputs::Vector{<:Real}; dif=1e-7, ignore_0_inputs=false)\n\nEstimate the gradient of f at inputs with forward differences\n\nExamples\n\njulia> f(x) = x[1] + x[2]^2;\n\njulia> isapprox([1,4], GPLinearODEMaker.est_∇(f, [2, 2.]); rtol=1e-5)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.est_∇nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"Diagnostic functions","title":"GPLinearODEMaker.est_∇nlogL_GLOM","text":"est_∇nlogL_GLOM(glo, total_hyperparameters; dif=1e-7)\n\nEstimate the gradient of nlogL_GLOM(glo, total_hyperparameters) with forward differences\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.est_∇∇-Tuple{Function,Array{var\"#s89\",1} where var\"#s89\"<:Real}","page":"Diagnostic functions","title":"GPLinearODEMaker.est_∇∇","text":"est_∇∇(g::Function, inputs::Vector{<:Real}; dif=1e-7, ignore_0_inputs=false)\n\nEstimate the Hessian of a function whose gradients are provided by g at inputs with forward differences\n\nExamples\n\njulia> g(x) = [(x[2] ^ 2) / 2, x[1] * x[2]];  # h(x) = [0 x[2], x[2] x[1]]\n\njulia> isapprox([0. 9; 9 4], GPLinearODEMaker.est_∇∇(g, [4., 9]); rtol=1e-5)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.est_∇∇_from_f-Tuple{Function,Array{var\"#s89\",1} where var\"#s89\"<:Real}","page":"Diagnostic functions","title":"GPLinearODEMaker.est_∇∇_from_f","text":"est_∇∇_from_f(f::Function, inputs::Vector{<:Real}; dif=1e-7, ignore_0_inputs=false)\n\nEstimate the Hessian of f at inputs with forward differences. WARNING: The result is very sensitive to dif\n\nExamples\n\njulia> f(x) = (x[1] * x[2] ^ 2) / 2;  # h(x) = [0 x[2], x[2] x[1]]\n\njulia> isapprox([0. 9; 9 4], GPLinearODEMaker.est_∇∇_from_f(f, [4., 9]; dif=1e-4); rtol=1e-3)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.est_∇∇nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"Diagnostic functions","title":"GPLinearODEMaker.est_∇∇nlogL_GLOM","text":"est_∇∇nlogL_GLOM(glo, total_hyperparameters; dif=1e-4)\n\nEstimate the Hessian of nlogL_GLOM(glo, total_hyperparameters) with forward differences\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.test_∇-Union{Tuple{T}, Tuple{Array{T,1},Array{T,1}}} where T<:Real","page":"Diagnostic functions","title":"GPLinearODEMaker.test_∇","text":"test_∇(est_G, G; print_stuff=true, function_name=\"function\")\n\nCheck if two gradient vectors (est_G and G) are approximately the same\n\nExamples\n\njulia> GPLinearODEMaker.test_∇([1., 2, 3], [1.0001, 2, 3]; print_stuff=false)\ntrue\njulia> GPLinearODEMaker.test_∇([1., 2, 3], [0., 2, 3]; print_stuff=false)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.test_∇nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"Diagnostic functions","title":"GPLinearODEMaker.test_∇nlogL_GLOM","text":"test_∇nlogL_GLOM(glo, kernel_hyperparameters; dif=1e-4, print_stuff=true)\n\nCheck if ∇nlogL_GLOM(glo, total_hyperparameters) is close to numerical estimates provided by est_∇nlogL_GLOM(glo, total_hyperparameters)\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.test_∇∇-Union{Tuple{T}, Tuple{Union{Array{T,2}, LinearAlgebra.Symmetric},Union{Array{T,2}, LinearAlgebra.Symmetric}}} where T<:Real","page":"Diagnostic functions","title":"GPLinearODEMaker.test_∇∇","text":"test_∇∇(est_H, H; print_stuff=true, function_name=\"function\", rtol=1e-3)\n\nCheck if two Hessian matrices (est_H and H) are approximately the same\n\nExamples\n\njulia> GPLinearODEMaker.test_∇∇([1. 2; 3 4], [1.0001 2; 3 4]; print_stuff=false)\ntrue\njulia> GPLinearODEMaker.test_∇∇([1. 2; 3 4], [0. 2; 3 4]; print_stuff=false)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"diagnostic/#GPLinearODEMaker.test_∇∇nlogL_GLOM-Union{Tuple{T}, Tuple{GPLinearODEMaker.GLO,Array{T,1}}} where T<:Real","page":"Diagnostic functions","title":"GPLinearODEMaker.test_∇∇nlogL_GLOM","text":"test_∇∇nlogL_GLOM(glo, kernel_hyperparameters; dif=1e-4, print_stuff=true)\n\nCheck if ∇∇nlogL_GLOM(glo, total_hyperparameters) is close to numerical estimates provided by est_∇∇nlogL_GLOM(glo, total_hyperparameters)\n\n\n\n\n\n","category":"method"},{"location":"gettingstarted/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"gettingstarted/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"The most current, tagged version of GPLinearODEMaker.jl can be easily installed using Julia's Pkg","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Pkg.add(\"GPLinearODEMaker\")","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you would like to contribute to the package, or just want to run the latest (untagged) version, you can use the following","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Pkg.develop(\"GPLinearODEMaker\")","category":"page"},{"location":"gettingstarted/#Example","page":"Getting Started","title":"Example","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Here's an example using sine and cosines as the outputs to be modelled. The f, g!, and h! functions at the end give the likelihood, gradient, and Hessian, respectively.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"import GPLinearODEMaker; GLOM = GPLinearODEMaker\n\nkernel, n_kern_hyper = GLOM.include_kernel(\"se\")\n\nn = 100\nxs = 20 .* sort(rand(n))\nnoise1 = 0.1 .* ones(n)\nnoise2 = 0.2 .* ones(n)\ny1 = sin.(xs) .+ (noise1 .* randn(n))\ny2 = cos.(xs) .+ (noise2 .* randn(n))\n\nys = collect(Iterators.flatten(zip(y1, y2)))\nnoise = collect(Iterators.flatten(zip(noise1, noise2)))\n\nglo = GLOM.GLO(kernel, n_kern_hyper, 2, 2, xs, ys; noise = noise, a=[[1. 0.1];[0.1 1]])\ntotal_hyperparameters = append!(collect(Iterators.flatten(glo.a)), [10])\nworkspace = GLOM.nlogL_matrix_workspace(glo, total_hyperparameters)\n\nfunction f(non_zero_hyper::Vector{T} where T<:Real) = GLOM.nlogL_GLOM!(workspace, glo, non_zero_hyper)  # feel free to add priors here to optimize on the posterior!\nfunction g!(G::Vector{T}, non_zero_hyper::Vector{T}) where T<:Real\n    G[:] = GLOM.∇nlogL_GLOM!(workspace, glo, non_zero_hyper)  # feel free to add priors here to optimize on the posterior!\nend\nfunction h!(H::Matrix{T}, non_zero_hyper::Vector{T}) where T<:Real\n    H[:, :] = GLOM.∇∇nlogL_GLOM!(workspace, glo, non_zero_hyper)  # feel free to add priors here to optimize on the posterior!\nend","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"You can use f, g!, and h! to optimize the GP hyperparameters with external packages like Optim.jl or Flux.jl","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"initial_x = GLOM.remove_zeros(total_hyperparameters)\n\nusing Optim\n\n# @time result = optimize(f, initial_x, NelderMead())  # slow or wrong\n# @time result = optimize(f, g!, initial_x, LBFGS())  # faster and usually right\n@time result = optimize(f, g!, h!, initial_x, NewtonTrustRegion())  # fastest and usually right\n\nfit_total_hyperparameters = GLOM.reconstruct_total_hyperparameters(glo, result.minimizer)","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Once you have the best fit hyperparameters, you can easily calculate the GP conditioned on the data (i.e. the GP posterior)","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"n_samp_points = convert(Int64, max(500, round(2 * sqrt(2) * length(glo.x_obs))))\nx_samp = collect(range(minimum(glo.x_obs); stop=maximum(glo.x_obs), length=n_samp_points))\nn_total_samp_points = n_samp_points * glo.n_out\nn_meas = length(glo.x_obs)\n\nmean_GP, σ, mean_GP_obs, Σ = GLOM.GP_posteriors(glo, x_samp, fit_total_hyperparameters; return_mean_obs=true)","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"and use Plots to visualize the results","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"using Plots\n\nfunction make_plot(output::Integer, label::String)\n    sample_output_indices = output:glo.n_out:n_total_samp_points\n    obs_output_indices = output:glo.n_out:length(ys)\n    p = scatter(xs, ys[obs_output_indices], yerror=noise1, label=label)\n    plot!(x_samp, mean_GP[sample_output_indices]; ribbon=σ[sample_output_indices], alpha=0.3, label=\"GP\")\n    return p\nend\n\nplot(make_plot(1, \"Sin\"), make_plot(2, \"Cos\"), layout=(2,1), size=(960,540))","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"(Image: Resulting plot)","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Another, more complicated example where GLOM is used for modelling stellar variability can be found at christiangil/GLOM_RV_Example","category":"page"},{"location":"gettingstarted/#Getting-Help","page":"Getting Started","title":"Getting Help","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"To get help on specific functionality you can either look up the information here, or if you prefer you can make use of Julia's native doc-system. For example here's how to get additional information on GPLinearODEMaker.GLO within Julia's REPL:","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"?GPLinearODEMaker.GLO","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you encounter a bug or would like to participate in the development of this package come find us on Github.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"christiangil/GPLinearODEMaker.jl","category":"page"},{"location":"utility/","page":"Utility functions","title":"Utility functions","text":"Modules = [GPLinearODEMaker]\nPages   = [\"src/general_functions.jl\"]","category":"page"},{"location":"utility/#Base.ndims-Union{Tuple{LinearAlgebra.Cholesky}, Tuple{T}} where T<:Real","page":"Utility functions","title":"Base.ndims","text":"ndims(A::Cholesky)\n\nExtends ndims to return 2 if passed a Cholesky object\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.assert_positive-Tuple","page":"Utility functions","title":"GPLinearODEMaker.assert_positive","text":"assert_positive(vars...)\n\nExamples\n\njulia> GPLinearODEMaker.assert_positive([1,2,3,4])\n\njulia> GPLinearODEMaker.assert_positive([-1,2,3,4])\nERROR: AssertionError: passed a negative/0 variable that needs to be positive\n[...]\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.auto_addprocs-Tuple{}","page":"Utility functions","title":"GPLinearODEMaker.auto_addprocs","text":"auto_addprocs(;add_procs=0)\n\nAdds either as many workers as there are CPU threads minus 2 if none are active or the amount specified by add_procs\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.log_laplace_approximation-Union{Tuple{T}, Tuple{Union{Array{T,2}, LinearAlgebra.Symmetric},Real,Real}} where T<:Real","page":"Utility functions","title":"GPLinearODEMaker.log_laplace_approximation","text":"log_laplace_approximation(H, g, logh; λ=1)\n\nCompute the logarithm of the Laplace approxmation for the integral of a function of the following form ∫ exp(-λ g(y)) h(y) dy ≈ exp(-λ g(y)) h(y) (2π/λ)^(d/2) |H(y)|^(-1/2) where y is the value of y at the global mode and H is the (Hessian) matrix of second order partial derivatives of g(y) (see slide 10 of http://www.stats.ox.ac.uk/~steffen/teaching/bs2HT9/laplace.pdf). When used to calculate evidences, one can set λ = 1, g(y) = -log-likelihood, h(y) = model prior, and H(y) = the Fisher information matrix (FIM) or the Hessian matrix of the negative log-likelihood. Could possiblly improve with methods from Ruli et al. 2016 (https://arxiv.org/pdf/1502.06440.pdf)?\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.powers_of_negative_one-Tuple{Integer}","page":"Utility functions","title":"GPLinearODEMaker.powers_of_negative_one","text":"powers_of_negative_one(power)\n\nFinds -1 ^ power without calling ^\n\nExamples\n\njulia> GPLinearODEMaker.powers_of_negative_one(0) == GPLinearODEMaker.powers_of_negative_one(2) == 1\ntrue\njulia> GPLinearODEMaker.powers_of_negative_one(1) == GPLinearODEMaker.powers_of_negative_one(3) == -1\ntrue\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.reconstruct_array-Union{Tuple{T}, Tuple{Any,Array{T,2}}} where T<:Real","page":"Utility functions","title":"GPLinearODEMaker.reconstruct_array","text":"reconstruct_array(non_zero_entries, template_A)\n\nFill a matrix with non_zero_entries at the locations of the non-zero entries in template_A\n\nExamples\n\njulia> template_A = [4. 0;5 0];\n\njulia> non_zero_entries = [2., 3];\n\njulia> GPLinearODEMaker.reconstruct_array(non_zero_entries, template_A)\n2×2 Array{Float64,2}:\n 2.0  0.0\n 3.0  0.0\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.remove_zeros-Tuple{Array{T,1} where T<:Real}","page":"Utility functions","title":"GPLinearODEMaker.remove_zeros","text":"remove_zeros(V)\n\nReturn the a version of the passed vector after removing all zero entries. Could possibly be replaced with a view-based version.\n\nExamples\n\njulia> V = [1, 2, 0, 3, 0, 4, 5];\n\njulia> GPLinearODEMaker.remove_zeros(V)\n5-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.ridge_chol-Union{Tuple{Union{Array{T,2}, LinearAlgebra.Symmetric}}, Tuple{T}} where T<:Real","page":"Utility functions","title":"GPLinearODEMaker.ridge_chol","text":"ridge_chol(A)\n\nPerform a Cholesky factorization on A, adding a small ridge when necessary\n\nExamples\n\njulia> A = [4. 2;2 10];\n\njulia> GPLinearODEMaker.ridge_chol(A)\nLinearAlgebra.Cholesky{Float64,Array{Float64,2}}\nU factor:\n2×2 LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}:\n 2.0  1.0\n  ⋅   3.0\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.sendto-Union{Tuple{Union{Array{T,1}, T}}, Tuple{T}} where T<:Integer","page":"Utility functions","title":"GPLinearODEMaker.sendto","text":"sendto(workers; args...)\n\nSend the args to the workers specified by thier number IDs. Stolen shamelessly from ParallelDataTransfer.jl\n\nExamples\n\njulia> sendto([1, 2], x=100, y=rand(2, 3));\n\njulia> z = randn(10, 10); sendto(workers(), z=z);\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.symmetric_A-Union{Tuple{Union{Array{T,2}, LinearAlgebra.Symmetric}}, Tuple{T}} where T<:Real","page":"Utility functions","title":"GPLinearODEMaker.symmetric_A","text":"symmetric_A(A; ignore_asymmetry=false, chol=false)\n\nCheck if A is approximately symmetric and then return a symmetrized version or, optionally, the Cholesky factorization\n\nExamples\n\njulia> A = [1. 1; 0 1];\n\njulia> GPLinearODEMaker.symmetric_A(A; ignore_asymmetry=true)\n2×2 LinearAlgebra.Symmetric{Float64,Array{Float64,2}}:\n 1.0  0.5\n 0.5  1.0\n\n\n\n\n\n","category":"method"},{"location":"utility/#GPLinearODEMaker.symmetrize_A-Union{Tuple{Union{Array{T,2}, LinearAlgebra.Symmetric}}, Tuple{T}} where T<:Real","page":"Utility functions","title":"GPLinearODEMaker.symmetrize_A","text":"symmetrize_A(A)\n\nSymmetrize A (i.e. add its transpose and divide by 2)\n\nExamples\n\njulia> A = [1. 1; 0 1];\n\njulia> GPLinearODEMaker.symmetrize_A(A)\n2×2 LinearAlgebra.Symmetric{Float64,Array{Float64,2}}:\n 1.0  0.5\n 0.5  1.0\n\n\n\n\n\n","category":"method"},{"location":"priors/#Prior-functions","page":"Prior functions","title":"Prior functions","text":"","category":"section"},{"location":"priors/","page":"Prior functions","title":"Prior functions","text":"Modules = [GPLinearODEMaker]\nPages   = [\"src/prior_functions.jl\"]","category":"page"},{"location":"priors/#GPLinearODEMaker.bvnormal_covariance-Tuple{Real,Real,Real}","page":"Prior functions","title":"GPLinearODEMaker.bvnormal_covariance","text":"bvnormal_covariance(σ11, σ22, ρ)\n\nConverting 2 standard deviations and their correlation into a bivariate covariance matrix and Cholesky factorizing the result.\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.gamma_mode_std_to_α_θ-Tuple{Real,Real}","page":"Prior functions","title":"GPLinearODEMaker.gamma_mode_std_to_α_θ","text":"gamma_mode_std_to_α_θ(m, σ)\n\nConvert a gamma distribution's mode and standard deviation into it's shape and scale parameters\n\nArguments\n\nm::Real: Desired mode of gamma distribution\nσ::Real: Desired standard deviation of gamma distribution\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.gauss_cdf-Tuple{Real}","page":"Prior functions","title":"GPLinearODEMaker.gauss_cdf","text":"gauss_cdf(x)\n\nThe CDF of a Gaussian (i.e. (1 + erf(x))/2)\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_Rayleigh-Tuple{Real,Real}","page":"Prior functions","title":"GPLinearODEMaker.log_Rayleigh","text":"log_Rayleigh(x, σ; d=0, cutoff=Inf)\n\nLog of the Rayleigh PDF. https://en.wikipedia.org/wiki/Rayleigh_distribution\n\nArguments\n\nx::Real: Input\nσ::Real: The mode\nd::Integer=0: How many derivatives to take\ncutoff::Real=Inf: Where to cutoff the tail of the distribution\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_bvnormal-Union{Tuple{T}, Tuple{Array{T,1},LinearAlgebra.Cholesky}} where T<:Real","page":"Prior functions","title":"GPLinearODEMaker.log_bvnormal","text":"log_bvnormal(xs, Σ; μ=zeros(T, 2), d=[0,0], lows=zeros(T, 2) .- Inf)\n\nLog of the bivariate normal PDF NOTE THAT THAT WHEN USING lows!=[-∞,...], THIS IS NOT PROPERLY NORMALIZED\n\nArguments\n\nxs::Real: Inputs\nΣ::Colesky: The covariance matrix of the distribution\nμ::Vector=zeros(T, 2): The mean of the distribution\nd::Vector{<:Integer}=[0,0]: How many derivatives to take\nlows::Vector=zeros(T, 2) .- Inf: The lower cutoffs of the distribution\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_circle-Tuple{Array{var\"#s83\",1} where var\"#s83\"<:Real,Array{var\"#s82\",1} where var\"#s82\"<:Real}","page":"Prior functions","title":"GPLinearODEMaker.log_circle","text":"log_circle(xs, min_max_r; d=[0,0])\n\nLog of the 2D circle PDF.\n\nArguments\n\nxs::Real: Inputs\nmin_max_r::Vector{<:Real}: How far the inner and outer edge of the circle extends from the origin\nd::Vector{<:Integer}=[0,0]: How many derivatives to take\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_cone-Tuple{Array{var\"#s87\",1} where var\"#s87\"<:Real}","page":"Prior functions","title":"GPLinearODEMaker.log_cone","text":"log_cone(xs; d=[0,0])\n\nLog of the 2D unit cone PDF.\n\nArguments\n\nxs::Real: Inputs\nd::Vector{<:Integer}=[0,0]: How many derivatives to take\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_cubic_cone-Tuple{Array{var\"#s87\",1} where var\"#s87\"<:Real}","page":"Prior functions","title":"GPLinearODEMaker.log_cubic_cone","text":"log_cubic_cone(xs; d=[0,0])\n\nLog of the 2D unit cubic cone PDF.\n\nArguments\n\nxs::Real: Inputs\nd::Vector{<:Integer}=[0,0]: How many derivatives to take\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_gamma-Tuple{Real,Array{var\"#s90\",1} where var\"#s90\"<:Real}","page":"Prior functions","title":"GPLinearODEMaker.log_gamma","text":"log_gamma(x, parameters; d=0, passed_mode_std=false)\n\nLog of the Gamma PDF. Equivalent to using Distributions; logpdf(Gamma(α, θ), x) https://en.wikipedia.org/wiki/Gamma_distribution\n\nArguments\n\nx::Real: Input\nparameters::Vector: Either the shape and scale parameters (i.e. [α, θ]) or a mode and standard deviation\nd::Integer=0: How many derivatives to take\npassed_mode_std::Bool=false: Whether to the parameters need to be converted to shape and scale parameters\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_gaussian-Tuple{Real,Array{var\"#s90\",1} where var\"#s90\"<:Real}","page":"Prior functions","title":"GPLinearODEMaker.log_gaussian","text":"log_gaussian(x, parameters; d=0, min=-Inf, max=Inf)\n\nLog of the Gaussian PDF. Equivalent to using Distributions; logpdf(Gaussian(μ, σ), x)\n\nArguments\n\nx::Real: Input\nparameters::Vector: The mean and standard deviation parameters (i.e. [μ, σ])\nd::Integer=0: How many derivatives to take\nmin::Real=-Inf: Where to minimally truncate the Gaussian\nmax::Real=Inf: Where to maximally truncate the Gaussian\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_inverse_gamma-Tuple{Real}","page":"Prior functions","title":"GPLinearODEMaker.log_inverse_gamma","text":"log_inverse_gamma(x; α=1., β=1., d=0)\n\nLog of the InverseGamma PDF. Equivalent to using Distributions; logpdf(InverseGamma(α, β), x) https://en.wikipedia.org/wiki/Inverse-gamma_distribution\n\nKeyword Arguments\n\nx::Real: Input\nα::Real=1.: Shape parameter\nβ::Real=1.: Scale parameter\nd::Integer=0: How many derivatives to take\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_loguniform-Tuple{Real,Array{var\"#s89\",1} where var\"#s89\"<:Real}","page":"Prior functions","title":"GPLinearODEMaker.log_loguniform","text":"log_loguniform(x::Real, min_max::Vector{<:Real}; d::Integer=0, shift::Real=0)\n\nLog of the log-Uniform PDF. Flattens out in log space starting at shift Also known as a (modified in shifted case) Jeffrey's prior\n\nArguments\n\nx::Real: Input\nmin_max::Vector: Where to truncate the log-Uniform\nd::Integer=0: How many derivatives to take\nshift::Real=0: Where to shift the peak of the distribution\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_quad_cone-Tuple{Array{var\"#s87\",1} where var\"#s87\"<:Real}","page":"Prior functions","title":"GPLinearODEMaker.log_quad_cone","text":"log_quad_cone(xs; d=[0,0])\n\nLog of the 2D unit quadratic cone PDF.\n\nArguments\n\nxs::Real: Inputs\nd::Vector{<:Integer}=[0,0]: How many derivatives to take\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_rot_Rayleigh-Tuple{Array{var\"#s87\",1} where var\"#s87\"<:Real,Real}","page":"Prior functions","title":"GPLinearODEMaker.log_rot_Rayleigh","text":"log_rot_Rayleigh(xs; d=[0,0], σ=1/5, cutoff=Inf)\n\nLog of the 2D rotated Rayleigh PDF\n\nArguments\n\nxs::Real: Inputs\nd::Vector{<:Integer}=[0,0]: How many derivatives to take\nσ::Real=1/5: the radial mode of the distribution\ncutoff::Real=Inf: Where to cutoff the tail of the distribution\n\n\n\n\n\n","category":"method"},{"location":"priors/#GPLinearODEMaker.log_uniform-Tuple{Real}","page":"Prior functions","title":"GPLinearODEMaker.log_uniform","text":"log_uniform(x; d=0, min=0, max=1)\n\nLog of the Uniform PDF.\n\nArguments\n\nx::Real: Input\nmin_max::Vector=[0,1]: Where to truncate the Uniform\nd::Integer=0: How many derivatives to take\n\n\n\n\n\n","category":"method"},{"location":"LICENSE/#LICENSE","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/","page":"LICENSE","title":"LICENSE","text":"using Markdown, GPLinearODEMaker\nMarkdown.parse_file(joinpath(pkgdir(GPLinearODEMaker), \"LICENSE.md\"))","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = GPLinearODEMaker","category":"page"},{"location":"#GPLinearODEMaker.jl-Documentation","page":"Home","title":"GPLinearODEMaker.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"GPLinearODEMaker (GLOM) is a package for finding the likelihood (and derivatives thereof) of multivariate Gaussian processes (GP) that are composed of a linear combination of a univariate GP and its derivatives.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: q_0(t) = m_0(t) + a_{00}X(t) + a_{01}\\dot{X}(t) + a_{02}\\ddot{X}(t))","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: q_1(t) = m_1(t) + a_{10}X(t) + a_{11}\\dot{X}(t) + a_{12}\\ddot{X}(t))","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: \\vdots)","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: q_l(t) = m_l(t) + a_{l0}X(t) + a_{l1}\\dot{X}(t) + a_{l2}\\ddot{X}(t))","category":"page"},{"location":"","page":"Home","title":"Home","text":"where each X(t) is the latent GP and the qs are the time series of the outputs.","category":"page"},{"location":"#Where-to-begin?","page":"Home","title":"Where to begin?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you haven't used GLOM before, a good place to start is the \"Getting Started\" section. We list how to install the package as well as a simple example","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"gettingstarted.md\"]\nDepth = 2","category":"page"},{"location":"#User's-Guide","page":"Home","title":"User's Guide","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Using GLOM generally starts with choosing a kernel function (possibly with include_kernel)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"kernel.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"kernel_creation.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"and creating a GLO object.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"glo.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Several kernel functions have been created already and are stored in src/kernels. Once one has a GLO, the covariances, likelihoods, and their derivatives can be easily calculated using GLOM","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"nlogl.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"In addition, we have also provided some possible reasonable priors that can be used for the kernel hyperparameters","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"priors.md\"]\nDepth = 2","category":"page"},{"location":"#Citing-GLOM","page":"Home","title":"Citing GLOM","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use GPLinearODEMaker.jl in your work, please cite the following BibTeX entry","category":"page"},{"location":"","page":"Home","title":"Home","text":"@ARTICLE{2020ApJ...905..155G,\n       author = {{Gilbertson}, Christian and {Ford}, Eric B. and {Jones}, David E. and {Stenning}, David C.},\n        title = \"{Toward Extremely Precise Radial Velocities. II. A Tool for Using Multivariate Gaussian Processes to Model Stellar Activity}\",\n      journal = {\\apj},\n     keywords = {Exoplanet detection methods, Astronomy software, Stellar activity, Gaussian Processes regression, Time series analysis, 489, 1855, 1580, 1930, 1916, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Earth and Planetary Astrophysics, Astrophysics - Solar and Stellar Astrophysics},\n         year = 2020,\n        month = dec,\n       volume = {905},\n       number = {2},\n          eid = {155},\n        pages = {155},\n          doi = {10.3847/1538-4357/abc627},\narchivePrefix = {arXiv},\n       eprint = {2009.01085},\n primaryClass = {astro-ph.IM},\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2020ApJ...905..155G},\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}","category":"page"},{"location":"#Indices","page":"Home","title":"Indices","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All of the package functions and types can be found here","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"indices.md\"]","category":"page"},{"location":"#Documentation-Acknowledgments","page":"Home","title":"Documentation Acknowledgments","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Thanks to Documenter.jl for making Julia documentation easier and Augmentor.jl for documentation inspiration.","category":"page"},{"location":"kernel/#Kernel-functions","page":"Kernel functions","title":"Kernel functions","text":"","category":"section"},{"location":"kernel/","page":"Kernel functions","title":"Kernel functions","text":"Here are the current base kernel functions that were used to construct the src/kernels kernel functions","category":"page"},{"location":"kernel/","page":"Kernel functions","title":"Kernel functions","text":"Modules = [GPLinearODEMaker]\nPages   = [\"src/kernel_base_functions.jl\"]","category":"page"},{"location":"kernel/#GPLinearODEMaker.matern52_kernel_base-Tuple{Number,Number}","page":"Kernel functions","title":"GPLinearODEMaker.matern52_kernel_base","text":"matern52_kernel_base(λ, δ)\n\nMatern 5/2 kernel. Twice mean square differentiable\n\nArguments\n\nλ::Number: The kernel lengthscale\nδ::Number: The difference between the inputs (e.g. t1 - t2)\n\n\n\n\n\n","category":"method"},{"location":"kernel/#GPLinearODEMaker.pp_kernel_base-Tuple{Number,Number}","page":"Kernel functions","title":"GPLinearODEMaker.pp_kernel_base","text":"pp_kernel_base(λ, δ)\n\nPiecewise polynomial kernel. Twice mean square differentiable. Equation 4.21 in Rasmussen and Williams.\n\nArguments\n\nλ::Number: The kernel lengthscale, and cutoff variable\nδ::Number: The difference between the inputs (e.g. t1 - t2)\n\n\n\n\n\n","category":"method"},{"location":"kernel/#GPLinearODEMaker.rm52_kernel_base-Tuple{Array{var\"#s92\",1} where var\"#s92\"<:Number,Number}","page":"Kernel functions","title":"GPLinearODEMaker.rm52_kernel_base","text":"rq_kernel_base(hyperparameters, δ)\n\nRational Matern 5/2 kernel. Equivalent to adding together Matern 5/2 kernels with the inverse of the lengthscale (τ = M52_λ^-1) are distributed as a Gamma distribution of p(τ|α,μ) where α (sometimes written as k) is the shape parameter and μ is the mean of the distribution.\n\nArguments\n\nhyperparameters::Vector: The kernel shape parameter and mean (i.e. [α, μ])\nδ::Number: The difference between the inputs (e.g. t1 - t2)\n\n\n\n\n\n","category":"method"},{"location":"kernel/#GPLinearODEMaker.rq_kernel_base-Tuple{Array{var\"#s92\",1} where var\"#s92\"<:Number,Number}","page":"Kernel functions","title":"GPLinearODEMaker.rq_kernel_base","text":"rq_kernel_base(hyperparameters, δ)\n\nRational Quadratic kernel. Equivalent to adding together SE kernels with the inverse square of the lengthscales (τ = SE_λ^-2) are distributed as a Gamma distribution of p(τ|α,μ) where α (sometimes written as k) is the shape parameter and μ is the mean of the distribution. When α→∞, the RQ is identical to the SE with λ = μ^-1/2.\n\nArguments\n\nhyperparameters::Vector: The kernel shape parameter and mean (i.e. [α, μ])\nδ::Number: The difference between the inputs (e.g. t1 - t2)\n\n\n\n\n\n","category":"method"},{"location":"kernel/#GPLinearODEMaker.se_kernel_base-Tuple{Number,Number}","page":"Kernel functions","title":"GPLinearODEMaker.se_kernel_base","text":"se_kernel_base(λ, δ)\n\nSquared exonential GP kernel (~Gaussian). Infinitely mean square differentiable (a.k.a. very smooth).\n\nArguments\n\nλ::Number: The kernel lengthscale\nδ::Number: The difference between the inputs (e.g. t1 - t2)\n\n\n\n\n\n","category":"method"},{"location":"kernel/","page":"Kernel functions","title":"Kernel functions","text":"All of the premade kernels that are included with GLOM (in src/kernels) were created with this example script","category":"page"}]
}
